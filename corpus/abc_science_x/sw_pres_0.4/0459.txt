a robot army won ' t look like what we have come to expect from the movies a robot army could never be held morally responsible for committing war crimes , says an australian ethicist , and so any wars they fight could be considered unjust . dr robert sparrow of monash university , who specialises in the ethics of new technologies , will lay out his argument in the journal of applied philosophy . " to fight a war properly you must always be able to identify somebody who is responsible for the deaths that ensue ," says sparrow , who is also with the centre for applied philosophy and public ethics at the university of melbourne . " as this condition cannot be met in relation to deaths caused by an autonomous weapon system it would therefore be unethical to deploy such systems in warfare ." sparrow ' s article was triggered by his discovery that the military is the largest funder of robotics research . for example , he says , the us military is developing an army that places autonomous machines in key roles on the front line . currently , the army uses semi - autonomous robots in mine clearing and bomb disposal . and for any machine that kills people , there is always a human being that can be held morally responsible , says sparrow . he says this applies , for example , to unmanned combat aerial vehicles that are programmed to help locate specific targets and fire on them , currently used in the middle east conflict . but , asks sparrow , what would happen if machines themselves were given the decision about who to kill ? autonomous killing machines having killer robots on the front line instead of young men and women may be more politically acceptable , but will this mean any war crimes could be blamed on the machines , asks sparrow ? being than because or theirs this yours